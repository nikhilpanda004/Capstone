{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q: Find the actor named \"Tom Hanks\".\n",
        "\n",
        "A: MATCH (tom {name: \"Tom Hanks\"}) RETURN tom\n",
        "\n",
        "Q: Find the movie with title \"Cloud Atlas\"...\n",
        "\n",
        "A: MATCH (cloudAtlas {title: \"Cloud Atlas\"}) RETURN cloudAtlas\n",
        "\n",
        "Q: Find 10 people...\n",
        "\n",
        "A: MATCH (people:Person) RETURN people.name LIMIT 10\n",
        "\n",
        "Q: Find movies released in the 1990s...\n",
        "\n",
        "A: MATCH (nineties:Movie) WHERE nineties.released >= 1990 AND nineties.released < 2000 RETURN nineties.title\n",
        "\n",
        "Q: List all Tom Hanks movies...\n",
        "\n",
        "A: MATCH (tom:Person {name: \"Tom Hanks\"})-[:ACTED_IN]->(tomHanksMovies) RETURN tom,tomHanksMovies\n",
        "\n",
        "Q: Who directed \"Cloud Atlas\"?\n",
        "\n",
        "A: MATCH (cloudAtlas {title: \"Cloud Atlas\"})<-[:DIRECTED]-(directors) RETURN directors.name\n",
        "\n",
        "Q: Tom Hanks' co-actors...\n",
        "\n",
        "A: MATCH (tom:Person {name:\"Tom Hanks\"})-[:ACTED_IN]->(m)<-[:ACTED_IN]-(coActors) RETURN coActors.name\n",
        "\n",
        "Q: How people are related to \"Cloud Atlas\"...\n",
        "\n",
        "A: MATCH (people:Person)-[relatedTo]-(:Movie {title: \"Cloud Atlas\"}) RETURN people.name, Type(relatedTo), relatedTo\n",
        "\n",
        "Q: Movies and actors up to 4 \"hops\" away from Kevin Bacon\n",
        "\n",
        "A: MATCH (bacon:Person {name:\"Kevin Bacon\"})-[*1..4]-(hollywood) RETURN DISTINCT hollywood\n",
        "\n",
        "Q: Bacon path, the shortest path of any relationships to Meg Ryan\n",
        "\n",
        "A: MATCH p=shortestPath(\n",
        "(bacon:Person {name:\"Kevin Bacon\"})-[*]-(meg:Person {name:\"Meg Ryan\"})\n",
        ")\n",
        "RETURN p\n",
        "\n",
        "Q: Delete all Movie and Person nodes, and their relationships\n",
        "\n",
        "A: MATCH (n) DETACH DELETE n\n",
        "\n",
        "Q: Prove that the Movie Graph is gone\n",
        "\n",
        "A: MATCH (n) RETURN n\n",
        "\n",
        "Q: Shortest path\n",
        "\n",
        "A: MATCH (martin:RoadNode),(oliver:RoadNode),\n",
        "p = shortestPath((martin)-[*..15]-(oliver))\n",
        "WHERE id(martin) = 16814 AND id(oliver) = 16820\n",
        "RETURN p"
      ],
      "metadata": {
        "id": "m5GCG7r_012N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm\n",
        "#!python -m spacy download en_core_web_trf\n",
        "!python -m spacy download en_core_web_lg\n",
        "#!pip install tensorflow\n",
        "#!pip install TensorRT\n",
        "#!pip install spacy-transformers\n",
        "#!python -m spacy download en_core_web_trf"
      ],
      "metadata": {
        "id": "IP6aiSoIUBR3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6df497a-9af3-4d77-87d9-d89eef86fd03"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-11 19:24:25.943325: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-11 19:24:28.216667: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-sm==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.5.0) (3.5.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.11)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.1.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "2023-07-11 19:24:42.473614: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-11 19:24:43.487956: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-lg==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.5.0/en_core_web_lg-3.5.0-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-lg==3.5.0) (3.5.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (8.1.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.10.11)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.1.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (8.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.1.3)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.5.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_templates = {\n",
        "    'find_person': \"MATCH (p:Person) WHERE p.name =~ '(?i){name}' RETURN p\",\n",
        "    'find_movie': \"MATCH (m:Movie) WHERE m.title =~ '(?i){name}' RETURN m\",\n",
        "    'find_movie_by_relation': \"MATCH q=(p:Person)-[r]->(m:Movie) WHERE type(r) in [{relationships}] and {where_clause} RETURN q\",\n",
        "    'find_all_movie_person': \"Match q=(p:Person)-[]->(m:Movie) {where_clause} return q\",\n",
        "    'find_persons': \"MATCH (p:Person) {where_clause} RETURN p\",\n",
        "    'find_movies': \"MATCH (m:Movie) {where_clause} RETURN m\",\n",
        "    # 'shortest_path_between_two': \"MATCH (({first_node}) {where_clause_1}), (({second_node}) {where_clause_2}), q = shortestPath(({first_node_nt})-[*..{hops}]-({second_node_nt})) RETURN q\",\n",
        "    'shortest_path_between_two': \"MATCH ({first_node}), ({second_node}), q = shortestPath(({first_node_nt})-[*..{hops}]-({second_node_nt})) WHERE {where_clause_1} AND {where_clause_2} RETURN q\",\n",
        "    'shortest_path_from_node': \"MATCH q = shortestPath({first_node}-[*..{hops}]-(p)) {where_clause} RETURN p\",\n",
        "    'hops_from_node': \"MATCH ({first_node})-[*1..{hops}]-(q) {where_clause} RETURN DISTINCT q\"\n",
        "}"
      ],
      "metadata": {
        "id": "kpkv1mi2TLk6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vmCUOfVLTFid"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, PunktSentenceTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import spacy\n",
        "import en_core_web_sm\n",
        "#import en_core_web_trf\n",
        "import en_core_web_lg\n",
        "from spacy.matcher import Matcher\n",
        "from spacy.pipeline import EntityRuler\n",
        "import re\n",
        "# Load the English language model in spaCy\n",
        "#nlp = spacy.load(\"en_core_web_sm\")\n",
        "nlp = spacy.load(\"en_core_web_lg\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Named Entity Recognition (NER) on the input text\n",
        "nlp.tokenizer.token_match = None  # Reset the tokenization patterns\n",
        "prefixes = list(nlp.Defaults.prefixes) + [r\"\\b[A-Z]\\w*(?:-[A-Z]\\w*)?$\"]  # Add a pattern for capitalized words\n",
        "suffixes = list(nlp.Defaults.suffixes) + [r\"(?:-[A-Z]\\w*)+\\b\"]  # Add a pattern for hyphenated words\n",
        "infixes = list(nlp.Defaults.infixes) + [r\"(?<=[a-zA-Z])-(?=[a-zA-Z])\"]  # Add a pattern for hyphen between words\n",
        "nlp.tokenizer.prefix_search = spacy.util.compile_prefix_regex(prefixes).search\n",
        "nlp.tokenizer.suffix_search = spacy.util.compile_suffix_regex(suffixes).search\n",
        "nlp.tokenizer.infix_finditer = spacy.util.compile_infix_regex(infixes).finditer\n",
        "\n",
        "if nlp.has_pipe(\"entity_ruler\"):\n",
        "  nlp.remove_pipe(\"entity_ruler\")\n",
        "ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\")\n",
        "movies_entries = [\"A Few Good Men\", \"The Matrix\",\"The Matrix Reloaded\",\"The Matrix Revolutions\",\"The Devil's Advocate\",\"A Few Good Men\",\"Top Gun\",\"Jerry Maguire\",\"Stand By Me\",\"As Good as It Gets\",\"What Dreams May Come\",\"Snow Falling on Cedars\",\"You've Got Mail\",\"Sleepless in Seattle\",\"Joe Versus the Volcano\",\"When Harry Met Sally\",\"That Thing You Do\",\"The Replacements\",\"RescueDawn\",\"The Birdcage\",\"Unforgiven\",\"Johnny Mnemonic\",\"Cloud Atlas\",\"The Da Vinci Code\",\"V for Vendetta\",\"Speed Racer\",\"Ninja Assassin\",\"The Green Mile\",\"Frost/Nixon\",\"Hoffa\",\"Apollo 13\",\"Twister\",\"Cast Away\",\"One Flew Over the Cuckoo's Nest\",\"Something's Gotta Give\",\"Bicentennial Man\",\"Charlie Wilson's War\",\"The Polar Express\",\"A League of Their Own\"]\n",
        "for movie in movies_entries:\n",
        "  ruler.add_patterns([{\"label\": \"WORK_OF_ART\", \"pattern\": movie.lower()}])\n",
        "\n",
        "person_entries = [\"Keanu Reeves\",\"Carrie-Anne Moss\",\"Laurence Fishburne\",\"Hugo Weaving\",\"Lilly Wachowski\",\"Lana Wachowski\",\"Joel Silver\",\"Emil Eifrem\",\"Charlize Theron\",\"Al Pacino\",\"Taylor Hackford\",\"Tom Cruise\",\"Jack Nicholson\",\"Demi Moore\",\"Kevin Bacon\",\"Kiefer Sutherland\",\"Noah Wyle\",\"Cuba Gooding Jr.\",\"Kevin Pollak\",\"J.T. Walsh\",\"James Marshall\",\"Christopher Guest\",\"Rob Reiner\",\"Aaron Sorkin\",\"Kelly McGillis\",\"Val Kilmer\",\"Anthony Edwards\",\"Tom Skerritt\",\"Meg Ryan\",\"Tony Scott\",\"Jim Cash\",\"Renee Zellweger\",\"Kelly Preston\",\"Jerry O'Connell\",\"Jay Mohr\",\"Bonnie Hunt\",\"Regina King\",\"Jonathan Lipnicki\",\"Cameron Crowe\",\"River Phoenix\",\"Corey Feldman\",\"Wil Wheaton\",\"John Cusack\",\"Marshall Bell\",\"Helen Hunt\",\"Greg Kinnear\",\"James L. Brooks\",\"Annabella Sciorra\",\"Max von Sydow\",\"Werner Herzog\",\"Robin Williams\",\"Vincent Ward\",\"Ethan Hawke\",\"Rick Yune\",\"James Cromwell\",\"Scott Hicks\",\"Parker Posey\",\"Dave Chappelle\",\"Steve Zahn\",\"Tom Hanks\",\"Nora Ephron\",\"Rita Wilson\",\"Bill Pullman\",\"Victor Garber\",\"Rosie O'Donnell\",\"John Patrick Stanley\",\"Nathan Lane\",\"Billy Crystal\",\"Carrie Fisher\",\"Bruno Kirby\",\"Liv Tyler\",\"Brooke Langton\",\"Gene Hackman\",\"Orlando Jones\",\"Howard Deutch\",\"Christian Bale\",\"Zach Grenier\",\"Mike Nichols\",\"Richard Harris\",\"Clint Eastwood\",\"Takeshi Kitano\",\"Dina Meyer\",\"Ice-T\",\"Robert Longo\",\"Halle Berry\",\"Jim Broadbent\",\"Tom Tykwer\",\"David Mitchell\",\"Stefan Arndt\",\"Ian McKellen\",\"Audrey Tautou\",\"Paul Bettany\",\"Ron Howard\",\"Natalie Portman\",\"Stephen Rea\",\"John Hurt\",\"Ben Miles\",\"Emile Hirsch\",\"John Goodman\",\"Susan Sarandon\",\"Matthew Fox\",\"Christina Ricci\",\"Rain\",\"Naomie Harris\",\"Michael Clarke Duncan\",\"David Morse\",\"Sam Rockwell\",\"Gary Sinise\",\"Patricia Clarkson\",\"Frank Darabont\",\"Frank Langella\",\"Michael Sheen\",\"Oliver Platt\",\"Danny DeVito\",\"John C. Reilly\",\"Ed Harris\",\"Bill Paxton\",\"Philip Seymour Hoffman\",\"Jan de Bont\",\"Robert Zemeckis\",\"Milos Forman\",\"Diane Keaton\",\"Nancy Meyers\",\"Chris Columbus\",\"Julia Roberts\",\"Madonna\",\"Geena Davis\",\"Lori Petty\",\"Penny Marshall\",\"Paul Blythe\",\"Angela Scope\",\"Jessica Thompson\",\"James Thompson\"]\n",
        "for person in person_entries:\n",
        "  ruler.add_patterns([{\"label\": \"PERSON\", \"pattern\": person.lower()}])"
      ],
      "metadata": {
        "id": "2uxJClVHTOGn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Relationship Extraction\n",
        "def relation_extraction(entities, verb_entities):\n",
        "    entities_labels = [item[1] for item in entities]\n",
        "    relationship_found = False\n",
        "    if ('MOVIE' in entities_labels or 'WORK_OF_ART' in entities_labels) or 'PERSON' in entities_labels:\n",
        "      if any(verb in verb_entities for verb in ['acted', 'act', 'perform', 'performed']):\n",
        "        entities.append(('ACTED_IN', 'RELATIONSHIP'))\n",
        "        relationship_found = True\n",
        "      if any(verb in verb_entities for verb in ['follows', 'followed', 'monitored']):\n",
        "        entities.append(('FOLLOWS', 'RELATIONSHIP'))\n",
        "        relationship_found = True\n",
        "      if any(verb in verb_entities for verb in ['directed', 'director', 'direction']):\n",
        "        entities.append(('DIRECTED', 'RELATIONSHIP'))\n",
        "        relationship_found = True\n",
        "      if any(verb in verb_entities for verb in ['produced', 'made', 'bank rolled', 'rolled']):\n",
        "        entities.append(('PRODUCED', 'RELATIONSHIP'))\n",
        "        relationship_found = True\n",
        "      if any(verb in verb_entities for verb in ['judged', 'review', 'reviewed']):\n",
        "        entities.append(('REVIEWED', 'RELATIONSHIP'))\n",
        "        relationship_found = True\n",
        "      if any(verb in verb_entities for verb in ['written', 'wrote', 'author', 'authored']):\n",
        "        entities.append(('WROTE', 'RELATIONSHIP'))\n",
        "        relationship_found = True\n",
        "    if not relationship_found and ('MOVIE' in entities_labels or 'WORK_OF_ART' in entities_labels) and 'PERSON' in entities_labels:\n",
        "      entities.append(('ALL', 'RELATIONSHIP'))\n",
        "    if relationship_found:\n",
        "      if sum(1 for entity in entities if entity[1] == 'PERSON') == 0:\n",
        "        entities.append(('', 'PERSON'))\n",
        "      elif sum(1 for entity in entities if entity[1] == 'MOVIE') == 0 and sum(1 for entity in entities if entity[1] == 'WORK_OF_ART') == 0:\n",
        "        entities.append(('', 'MOVIE'))\n",
        "    return entities\n",
        "\n",
        "\n",
        "def recognize_entities(text):\n",
        "    doc = nlp(text)\n",
        "    entities = []\n",
        "    for ent in doc.ents:\n",
        "        entities.append((ent.text, ent.label_))\n",
        "\n",
        "    verb_entities = []\n",
        "    for token in doc:\n",
        "        if token.pos_ == \"NOUN\" and token.text.lower() in [\"film\", \"movie\", \"films\", \"movies\", \"cinema\", \"cinemas\"]:\n",
        "          entities.append((\"\", \"MOVIE\"))\n",
        "        elif token.pos_ == \"NOUN\" and token.text.lower() in [\"actor\", \"actress\", \"star\", \"stars\", \"actors\", \"actresses\", \"people\"]:\n",
        "          entities.append((\"\", \"PERSON\"))\n",
        "        elif token.pos_ == \"NOUN\" and token.text.lower() in [\"hop\", \"hops\", \"step\", \"steps\", \"node\", \"nodes\"]:\n",
        "          entities.append((\"\", \"HOPS\"))\n",
        "        elif token.pos_ == \"ADJ\" and token.text.lower() in [\"closest\", \"close\", \"short\", \"shortest\", \"near\", \"nearest\"]:\n",
        "          entities.append((\"\", \"PATH\"))\n",
        "        elif token.pos_ == \"VERB\":\n",
        "          verb_entities.append(token.text.lower())\n",
        "        if token.dep_ == \"dobj\" and token.head.lower_ in [\"what\", \"where\", \"how\"]:\n",
        "            entities.append((token.text, \"QUESTION_OBJECT\"))\n",
        "        if (token.dep_ == 'compound'):\n",
        "          entities.append((token.text + ' ' + token.head.text , \"NAME\"))\n",
        "    entities = relation_extraction(entities, verb_entities)\n",
        "    if text.find(\"'\") > -1 and text.rfind(\"'\") < len(text):\n",
        "      start_index = text.find(\"'\") + 1\n",
        "      end_index = text.rfind(\"'\")\n",
        "      attribute = text[start_index:end_index]\n",
        "      entities.append((attribute, \"ATTRIBUTE\"))\n",
        "    return entities"
      ],
      "metadata": {
        "id": "wM6f08GkApXr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ner = nlp.get_pipe(\"ner\")\n",
        "# Get all the unique entity labels recognized by the NER component\n",
        "labels = ner.labels\n",
        "\n",
        "# Print the entity labels\n",
        "for label in labels:\n",
        "    print(label)"
      ],
      "metadata": {
        "id": "C-ObJC1E3EH1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16714ebf-a96a-4dec-eb77-ac56cd775fe1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CARDINAL\n",
            "DATE\n",
            "EVENT\n",
            "FAC\n",
            "GPE\n",
            "LANGUAGE\n",
            "LAW\n",
            "LOC\n",
            "MONEY\n",
            "NORP\n",
            "ORDINAL\n",
            "ORG\n",
            "PERCENT\n",
            "PERSON\n",
            "PRODUCT\n",
            "QUANTITY\n",
            "TIME\n",
            "WORK_OF_ART\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_cypher_query(text):\n",
        "  entities_mapping = {\n",
        "      'WORK_OF_ART': 'Movie',\n",
        "      'PERSON': 'Person',\n",
        "      'MOVIE': 'Movie'\n",
        "  }\n",
        "\n",
        "  entities = recognize_entities(text)\n",
        "  labels = [item[1] for item in entities]\n",
        "  query_template = ''\n",
        "  queries = []\n",
        "  relations_template = ''\n",
        "  limit_template = ''\n",
        "  for entity in entities:\n",
        "    (name, entity_label) = entity\n",
        "    # SHORTEST PATH\n",
        "    if entity_label == \"PATH\":\n",
        "      where_clause_1 = ''\n",
        "      where_clause_2 = ''\n",
        "      first_node = ''\n",
        "      second_node = ''\n",
        "      first_node_nt = ''\n",
        "      second_node_nt = ''\n",
        "\n",
        "      hops = 10\n",
        "      query_template = query_templates['shortest_path_between_two'] #'shortest_path_between_two': \"MATCH (({first_node}) {where_clause_1}), (({second_node}) {where_clause_2}), q = shortestPath(({first_node_nt})-[*..{hops}]-({second_node_nt})) RETURN q\",\n",
        "      # First node\n",
        "      for item, label in entities:\n",
        "        if label == \"PERSON\" and item != '':\n",
        "          first_node = \"p1:Person\"\n",
        "          first_node_nt = 'p1'\n",
        "          if where_clause_1 != '':\n",
        "            where_clause_1 += \" OR ANY(attribute IN keys(p1) WHERE p1[attribute] =~ '(?i)\" + item + \"')\"\n",
        "          else:\n",
        "            where_clause_1 = \"ANY(attribute IN keys(p1) WHERE p1[attribute] =~ '(?i)\" + item + \"')\"\n",
        "          entities.remove((item, label))\n",
        "          break\n",
        "        elif label == \"MOVIE\" and item != '':\n",
        "          first_node = \"m1:Movie\"\n",
        "          first_node_nt = 'm1'\n",
        "          if where_clause_1 != '':\n",
        "            where_clause_1 += \" OR ANY(attribute IN keys(m1) WHERE m1[attribute] =~ '(?i)\" + item + \"')\"\n",
        "          else:\n",
        "            where_clause_1 = \"ANY(attribute IN keys(m1) WHERE m1[attribute] =~ '(?i)\" + item + \"')\"\n",
        "          entities.remove((item, label))\n",
        "          break\n",
        "        elif label == \"WORK_OF_ART\" and item != '':\n",
        "          first_node = \"m1:Movie\"\n",
        "          first_node_nt = 'm1'\n",
        "          if where_clause_1 != '':\n",
        "            where_clause_1 += \" OR ANY(attribute IN keys(m1) WHERE m1[attribute] =~ '(?i)\" + item + \"')\"\n",
        "          else:\n",
        "            where_clause_1 = \"ANY(attribute IN keys(m1) WHERE m1[attribute] =~ '(?i)\" + item + \"')\"\n",
        "          entities.remove((item, label))\n",
        "          break\n",
        "\n",
        "      # Second node\n",
        "      for item, label in entities:\n",
        "        if label == \"PERSON\" and item != '':\n",
        "          second_node = \"p2:Person\"\n",
        "          second_node_nt = 'p2'\n",
        "          if where_clause_2 != '':\n",
        "            where_clause_2 += \" OR ANY(attribute IN keys(p2) WHERE p2[attribute] =~ '(?i)\" + item + \"')\"\n",
        "          else:\n",
        "            where_clause_2 = \"ANY(attribute IN keys(p2) WHERE p2[attribute] =~ '(?i)\" + item + \"')\"\n",
        "          entities.remove((item, label))\n",
        "          break\n",
        "        elif label == \"MOVIE\" and item != '':\n",
        "          second_node = \"m2:Movie\"\n",
        "          second_node_nt = 'm2'\n",
        "          if where_clause_2 != '':\n",
        "            where_clause_2 += \" OR ANY(attribute IN keys(m2) WHERE m2[attribute] =~ '(?i)\" + item + \"')\"\n",
        "          else:\n",
        "            where_clause_2 = \"ANY(attribute IN keys(m2) WHERE m2[attribute] =~ '(?i)\" + item + \"')\"\n",
        "          entities.remove((item, label))\n",
        "          break\n",
        "        elif label == \"WORK_OF_ART\" and item != '':\n",
        "          second_node = \"m2:Movie\"\n",
        "          second_node_nt = 'm2'\n",
        "          if where_clause_2 != '':\n",
        "            where_clause_2 += \" OR ANY(attribute IN keys(m2) WHERE m2[attribute] =~ '(?i)\" + item + \"')\"\n",
        "          else:\n",
        "            where_clause_2 = \"ANY(attribute IN keys(m2) WHERE m2[attribute] =~ '(?i)\" + item + \"')\"\n",
        "          entities.remove((item, label))\n",
        "          break\n",
        "\n",
        "      return query_template.replace('{first_node}', first_node).replace('{first_node_nt}', first_node_nt).replace('{second_node}', second_node).replace('{second_node_nt}', second_node_nt).replace('{where_clause_1}', where_clause_1).replace('{where_clause_2}', where_clause_2).replace('{hops}', str(hops))\n",
        "\n",
        "    # HOPS\n",
        "    if entity_label == \"HOPS\":\n",
        "      where_clause = ''\n",
        "      first_node = ''\n",
        "      query_template = query_templates['hops_from_node']\n",
        "      for item, label in entities:\n",
        "        if label == \"PERSON\" and item != '':\n",
        "          first_node = \"p:Person\"\n",
        "          if where_clause != '':\n",
        "            where_clause += \" OR ANY(attribute IN keys(p) WHERE p[attribute] =~ '(?i)\" + item + \"')\"\n",
        "          else:\n",
        "            where_clause = \"WHERE ANY(attribute IN keys(p) WHERE p[attribute] =~ '(?i)\" + item + \"')\"\n",
        "        elif label == \"MOVIE\" and item != '':\n",
        "          first_node = \"m:Movie\"\n",
        "          if where_clause != '':\n",
        "            where_clause += \" OR ANY(attribute IN keys(m) WHERE m[attribute] =~ '(?i)\" + item + \"')\"\n",
        "          else:\n",
        "            where_clause = \"WHERE ANY(attribute IN keys(m) WHERE m[attribute] =~ '(?i)\" + item + \"')\"\n",
        "        elif label == \"WORK_OF_ART\" and item != '':\n",
        "          first_node = \"m:Movie\"\n",
        "          if where_clause != '':\n",
        "            where_clause += \" OR ANY(attribute IN keys(m) WHERE m[attribute] =~ '(?i)\" + item + \"')\"\n",
        "          else:\n",
        "            where_clause = \"WHERE ANY(attribute IN keys(m) WHERE m[attribute] =~ '(?i)\" + item + \"')\"\n",
        "        elif label == \"CARDINAL\" and re.match(r'^\\d+$', item):\n",
        "          query_template = query_template.replace('{hops}', item)\n",
        "      return query_template.replace('{first_node}', first_node).replace('{where_clause}', where_clause)\n",
        "\n",
        "    # PERSON\n",
        "    if entity_label == 'PERSON' and sum(1 for entity in entities if entity[1] == 'RELATIONSHIP') == 0:\n",
        "      if name != '':\n",
        "        queries.append(query_templates['find_person'].replace('{name}', name))\n",
        "      else:\n",
        "        if sum(1 for entity in entities if entity[1] == 'NAME') == 0:\n",
        "          where_clause = ''\n",
        "          for item, label in entities:\n",
        "            if label in ['ATTRIBUTE', 'GPE']:\n",
        "              if where_clause != '':\n",
        "                where_clause += ' OR ' + \" ANY(attribute IN keys(p) WHERE p[attribute] =~ '(?i)\" + item + \"')\"\n",
        "              else:\n",
        "                where_clause += \"WHERE ANY(attribute IN keys(p) WHERE p[attribute] =~ '(?i)\" + item + \"')\" + where_clause\n",
        "            elif label in ['DATE']:\n",
        "              if where_clause != '':\n",
        "                where_clause += ' OR ' + \" ANY(attribute IN keys(p) WHERE p[attribute] = \" + item + \")\"\n",
        "              else:\n",
        "                where_clause += \"WHERE ANY(attribute IN keys(p) WHERE p[attribute] = \" + item + \")\" + where_clause\n",
        "          queries.append(query_templates['find_persons'].replace('{where_clause}', where_clause))\n",
        "        else:\n",
        "          for item, label in entities:\n",
        "            if label == 'NAME':\n",
        "              if name != '':\n",
        "                queries.append(query_templates['find_person'].replace('{name}', item))\n",
        "              elif sum(1 for entity in entities if entity[1] == 'PERSON') == 1:\n",
        "                queries.append(query_templates['find_persons'])\n",
        "              break\n",
        "    # WORK OF ART\n",
        "    elif entity_label == 'WORK_OF_ART' and sum(1 for entity in entities if entity[1] == 'RELATIONSHIP') == 0:\n",
        "      queries.append(query_templates['find_movie'].replace('{name}', name))\n",
        "    # MOVIE\n",
        "    elif entity_label == 'MOVIE' and sum(1 for entity in entities if entity[1] == 'RELATIONSHIP') == 0:\n",
        "      if sum(1 for entity in entities if entity[1] == 'NAME') == 0:\n",
        "        where_clause = ''\n",
        "        for item, label in entities:\n",
        "          if label in ['ATTRIBUTE', 'GPE']:\n",
        "            if where_clause != '':\n",
        "              where_clause += ' OR ' + \" ANY(attribute IN keys(m) WHERE m[attribute] =~ '(?i)\" + item + \"')\"\n",
        "            else:\n",
        "              where_clause += \"WHERE ANY(attribute IN keys(m) WHERE m[attribute] =~ '(?i)\" + item + \"')\" + where_clause\n",
        "          elif label in ['DATE']:\n",
        "            if where_clause != '':\n",
        "              where_clause += ' OR ' + \" ANY(attribute IN keys(m) WHERE m[attribute] = \" + item + \")\"\n",
        "            else:\n",
        "              where_clause += \"WHERE ANY(attribute IN keys(m) WHERE m[attribute] = \" + item + \")\" + where_clause\n",
        "        queries.append(query_templates['find_movies'].replace('{where_clause}', where_clause))\n",
        "      else:\n",
        "        for item, label in entities:\n",
        "          if label == 'NAME':\n",
        "            if name != '':\n",
        "              queries.append(query_templates['find_movie'].replace('{name}', item))\n",
        "            elif sum(1 for entity in entities if entity[1] in ['WORK_OF_ART', 'MOVIE']) == 1:\n",
        "              queries.append(query_templates['find_movies'])\n",
        "            break\n",
        "    # RELATIONSHIP\n",
        "    elif entity_label == 'RELATIONSHIP':\n",
        "      if name == 'ALL':\n",
        "        where_clause = ''\n",
        "        for item, label in entities:\n",
        "          if label == 'PERSON' and item != '':\n",
        "            if where_clause != '':\n",
        "              where_clause += 'OR ' + \" ANY(attribute IN keys(p) WHERE p[attribute] =~ '(?i)\" + item + \"')\"\n",
        "            else:\n",
        "              where_clause += \"WHERE ANY(attribute IN keys(p) WHERE p[attribute] =~ '(?i)\" + item + \"')\"\n",
        "          elif label == 'WORK_OF_ART' and item != '':\n",
        "            if where_clause != '':\n",
        "              where_clause += 'OR ' + \" ANY(attribute IN keys(m) WHERE m[attribute] =~ '(?i)\" + item + \"')\"\n",
        "            else:\n",
        "              where_clause += \"WHERE ANY(attribute IN keys(m) WHERE m[attribute] =~ '(?i)\" + item + \"')\"\n",
        "          elif label == \"NAME\" and item != '' and sum(1 for entity in entities if entity[1] == 'PERSON') == 1:\n",
        "            if where_clause != '':\n",
        "              where_clause += 'OR ' + \" ANY(attribute IN keys(p) WHERE p[attribute] =~ '(?i)\" + item + \"')\"\n",
        "            else:\n",
        "              where_clause += \"WHERE ANY(attribute IN keys(p) WHERE p[attribute] =~ '(?i)\" + item + \"')\"\n",
        "          elif label == \"NAME\" and item != '' and sum(1 for entity in entities if entity[1] == 'MOVIE') == 1:\n",
        "            if where_clause != '':\n",
        "              where_clause += 'OR ' + \" ANY(attribute IN keys(m) WHERE m[attribute] =~ '(?i)\" + item + \"')\"\n",
        "            else:\n",
        "              where_clause += \"WHERE ANY(attribute IN keys(m) WHERE m[attribute] =~ '(?i)\" + item + \"')\"\n",
        "        queries.append(query_templates['find_all_movie_person'].replace('{where_clause}', where_clause))\n",
        "      else:\n",
        "        if relations_template != '':\n",
        "          relations_template += \", '\" + name + \"'\"\n",
        "        else:\n",
        "          relations_template += \"'\" + name + \"'\"\n",
        "    # CARDINAL\n",
        "    elif entity_label == 'CARDINAL':\n",
        "      limit_template = ' LIMIT ' + name\n",
        "\n",
        "  # ALL RELATIONS\n",
        "  if 'RELATIONSHIP' in labels and relations_template != '':\n",
        "    where_clause = ''\n",
        "    for item, label in entities:\n",
        "      if label == 'PERSON' and item != '':\n",
        "        if where_clause != '':\n",
        "          where_clause += 'OR ' + \" ANY(attribute IN keys(p) WHERE p[attribute] =~ '(?i)\" + item + \"')\"\n",
        "        else:\n",
        "          where_clause += \" ANY(attribute IN keys(p) WHERE p[attribute] =~ '(?i)\" + item + \"')\"\n",
        "      elif label == 'WORK_OF_ART' and item != '':\n",
        "        if where_clause != '':\n",
        "          where_clause += 'OR ' + \" ANY(attribute IN keys(m) WHERE m[attribute] =~ '(?i)\" + item + \"')\"\n",
        "        else:\n",
        "          where_clause += \" ANY(attribute IN keys(m) WHERE m[attribute] =~ '(?i)\" + item + \"')\"\n",
        "      elif label == \"NAME\" and item != '' and sum(1 for entity in entities if entity[1] == 'PERSON') == 1:\n",
        "        if where_clause != '':\n",
        "          where_clause += 'OR ' + \" ANY(attribute IN keys(p) WHERE p[attribute] =~ '(?i)\" + item + \"')\"\n",
        "        else:\n",
        "          where_clause += \" ANY(attribute IN keys(p) WHERE p[attribute] =~ '(?i)\" + item + \"')\"\n",
        "      elif label == \"NAME\" and item != '' and sum(1 for entity in entities if entity[1] == 'MOVIE') == 1:\n",
        "        if where_clause != '':\n",
        "          where_clause += 'OR ' + \" ANY(attribute IN keys(m) WHERE m[attribute] =~ '(?i)\" + item + \"')\"\n",
        "        else:\n",
        "          where_clause += \" ANY(attribute IN keys(m) WHERE m[attribute] =~ '(?i)\" + item + \"')\"\n",
        "    queries.append(query_templates['find_movie_by_relation'].replace('{relationships}', relations_template).replace('{where_clause}', '(' + where_clause + ')'))\n",
        "\n",
        "  for query in queries:\n",
        "    if query_template != '':\n",
        "      query_template += ' UNION ' + query + limit_template\n",
        "    else:\n",
        "      query_template += query + limit_template\n",
        "\n",
        "  return query_template"
      ],
      "metadata": {
        "id": "lyl-vy9iy31Q"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Find the actor named Tom Hanks\"\n",
        "print(text)\n",
        "print(generate_cypher_query(text.lower()))\n",
        "print('------------------------------------------------')\n",
        "\n",
        "text = \"Find the movie with title Cloud Atlas\"\n",
        "print(text)\n",
        "print(generate_cypher_query(text.lower()))\n",
        "print('------------------------------------------------')\n",
        "\n",
        "text = \"Find 10 people born in 1929\"\n",
        "print(text)\n",
        "print(generate_cypher_query(text.lower()))\n",
        "print('------------------------------------------------')\n",
        "\n",
        "text = \"Find movies released in the 1990s ninties\"\n",
        "print(text)\n",
        "print(generate_cypher_query(text.lower()))\n",
        "print('------------------------------------------------')\n",
        "\n",
        "text = \"List all Tom Hanks movies\"\n",
        "print(text)\n",
        "print(generate_cypher_query(text.lower()))\n",
        "print('------------------------------------------------')\n",
        "\n",
        "text = \"Who directed Cloud Atlas?\"\n",
        "print(text)\n",
        "print(generate_cypher_query(text.lower()))\n",
        "print('------------------------------------------------')\n",
        "\n",
        "text = \"Tom Hanks co-actors\"\n",
        "print(text)\n",
        "print(generate_cypher_query(text.lower()))\n",
        "print('------------------------------------------------')\n",
        "\n",
        "text = \"How people are related to Cloud Atlas\"\n",
        "print(text)\n",
        "print(generate_cypher_query(text.lower()))\n",
        "print('------------------------------------------------')\n",
        "\n",
        "text = \"Movies and actors up to 4 hops away from Kevin Bacon\"\n",
        "print(text)\n",
        "print(generate_cypher_query(text.lower()))\n",
        "print('------------------------------------------------')\n",
        "\n",
        "# MATCH (bacon:Person {name:\"Kevin Bacon\"})-[*1..4]-(hollywood) RETURN DISTINCT hollywood\n",
        "\n",
        "text = \"Kevin Bacon, the shortest path of any relationships to Meg Ryan\"\n",
        "print(text)\n",
        "print(generate_cypher_query(text.lower()))\n",
        "print('------------------------------------------------')\n",
        "\n",
        "# MATCH p=shortestPath((bacon:Person {name:\"Kevin Bacon\"})-[*]-(meg:Person {name:\"Meg Ryan\"})) RETURN p\n",
        "\n",
        "# Shortest path\n",
        "\n",
        "# MATCH (martin:RoadNode),(oliver:RoadNode), p = shortestPath((martin)-[*..15]-(oliver))  WHERE id(martin) = 16814 AND id(oliver) = 16820 RETURN p"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxYg5kHx1vpU",
        "outputId": "34135708-f060-4af3-ca12-e345ae1a543e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Find the actor named Tom Hanks\n",
            "MATCH (p:Person) WHERE p.name =~ '(?i)tom hanks' RETURN p\n",
            "------------------------------------------------\n",
            "Find the movie with title Cloud Atlas\n",
            "MATCH (m:Movie) WHERE m.title =~ '(?i)cloud atlas' RETURN m\n",
            "------------------------------------------------\n",
            "Find 10 people born in 1929\n",
            "MATCH (p:Person) WHERE ANY(attribute IN keys(p) WHERE p[attribute] = 1929) RETURN p LIMIT 10\n",
            "------------------------------------------------\n",
            "Find movies released in the 1990s ninties\n",
            "MATCH (m:Movie)  RETURN m\n",
            "------------------------------------------------\n",
            "List all Tom Hanks movies\n",
            "Match q=(p:Person)-[]->(m:Movie) WHERE ANY(attribute IN keys(p) WHERE p[attribute] =~ '(?i)tom hanks')OR  ANY(attribute IN keys(p) WHERE p[attribute] =~ '(?i)tom hanks')OR  ANY(attribute IN keys(p) WHERE p[attribute] =~ '(?i)hanks movies') return q\n",
            "------------------------------------------------\n",
            "Who directed Cloud Atlas?\n",
            "MATCH q=(p:Person)-[r]->(m:Movie) WHERE type(r) in ['DIRECTED'] and ( ANY(attribute IN keys(m) WHERE m[attribute] =~ '(?i)cloud atlas')OR  ANY(attribute IN keys(p) WHERE p[attribute] =~ '(?i)cloud atlas')) RETURN q\n",
            "------------------------------------------------\n",
            "Tom Hanks co-actors\n",
            "MATCH (p:Person) WHERE p.name =~ '(?i)tom hanks' RETURN p\n",
            "------------------------------------------------\n",
            "How people are related to Cloud Atlas\n",
            "Match q=(p:Person)-[]->(m:Movie) WHERE ANY(attribute IN keys(m) WHERE m[attribute] =~ '(?i)cloud atlas')OR  ANY(attribute IN keys(p) WHERE p[attribute] =~ '(?i)cloud atlas') return q\n",
            "------------------------------------------------\n",
            "Movies and actors up to 4 hops away from Kevin Bacon\n",
            "MATCH (p:Person)-[*1..4]-(q) WHERE ANY(attribute IN keys(p) WHERE p[attribute] =~ '(?i)kevin bacon') RETURN DISTINCT q\n",
            "------------------------------------------------\n",
            "Kevin Bacon, the shortest path of any relationships to Meg Ryan\n",
            "MATCH (p1:Person), (p2:Person), q = shortestPath((p1)-[*..10]-(p2)) WHERE ANY(attribute IN keys(p1) WHERE p1[attribute] =~ '(?i)kevin bacon') AND ANY(attribute IN keys(p2) WHERE p2[attribute] =~ '(?i)meg ryan') RETURN q\n",
            "------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example text\n",
        "#text = \"Find the movie with title you've got mail\"\n",
        "#text = \"Find 10 people that are born in 1929\"\n",
        "#text = \"Find 10 movies that are released in 1929\"\n",
        "#text = \"Find the actor named Robert Downey Jr.\"\n",
        "#text = \"Find the movie with tagline 'Everything is connected' and corrected and released in 1929\"\n",
        "# text = \"List all Tom Hanks movies\"\n",
        "# text = \"Who directed Cloud Atlas?\"\n",
        "# text = \"How people are related to Cloud Atlas\"\n",
        "# text = \"Tom Hanks co-actors\" #imp\n",
        "text = 'Movies and actors within 4 nodes away from Tom Hanks' #hops, nodes, node, hop, steps, step\n",
        "#text = \"Bacon path, the shortest path of any relationships to Meg Ryan\"\n",
        "text = 'the short path between Joaael Silver and TOP GUN'\n",
        "text = text.lower()\n",
        "# Process the text\n",
        "doc = nlp(text)\n",
        "\n",
        "#Access dependency parse information\n",
        "# for token in doc:\n",
        "#     print(token.text, token.dep_, token.head.text)\n",
        "\n",
        "# for token in doc:\n",
        "#     print(token.text, token.pos_)\n",
        "\n",
        "# entities = recognize_entities(text)\n",
        "# print(entities)\n",
        "\n",
        "print(generate_cypher_query(text))\n",
        "\n",
        "# 'shortest_path_between_two': \"MATCH q = shortestPath({first_node}-[*..{hops}]-{second_node}) RETURN q\",\n",
        "#     'shortest_path_from_node': \"MATCH q = shortestPath({first_node}-[*..{hops}]-{second_node}) RETURN p\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aO5msDVp0-W5",
        "outputId": "82e5947a-5d59-4831-c261-928421e38336"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MATCH (p1:Person), (m2:Movie), q = shortestPath((p1)-[*..10]-(m2)) WHERE ANY(attribute IN keys(p1) WHERE p1[attribute] =~ '(?i)joaael silver') AND ANY(attribute IN keys(m2) WHERE m2[attribute] =~ '(?i)top gun') RETURN q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pickle\n",
        "\n",
        "# # Load the model from the pickle file\n",
        "# with open('nlp_model.pkl', 'rb') as f:\n",
        "#     nlp = pickle.load(f)\n",
        "\n",
        "# # Use the loaded NLP model\n",
        "# doc = nlp(\"Some text to process\")"
      ],
      "metadata": {
        "id": "LxVP7cF5oYHL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pickle\n",
        "\n",
        "# # Save the model using pickle\n",
        "# with open('nlp_model.pkl', 'wb') as f:\n",
        "#     pickle.dump(nlp, f)\n"
      ],
      "metadata": {
        "id": "Zc8S_VzloiOT"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}